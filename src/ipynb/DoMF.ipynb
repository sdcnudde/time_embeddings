{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from azure.storage.blob import BlobService\n",
    "import pyspark\n",
    "#from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import time\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "conf = (SparkConf().set(\"spark.driver.maxResultSize\", \"8g\"))\n",
    "print conf.get(\"spark.num-executors\")\n",
    "conf = (SparkConf().set(\"spark.num-executors\", \"4\"))\n",
    "conf = (SparkConf().set(\"spark.driver-cores\", \"4\"))\n",
    "conf = (SparkConf().set(\"spark.num-executors\", \"40\"))\n",
    "conf = (SparkConf().set(\"spark.executor-cores\", \"4\"))\n",
    "conf = (SparkConf().set(\"spark.executor-memory\", \"16G\"))\n",
    "conf = (SparkConf().set(\"spark.driver-memory\", \"16G\"))\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"do_mf\").config(conf=conf).getOrCreate()\n",
    "print conf.get(\"spark.driver-memory\")\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "block_blob_service_sample = BlobService(account_name='asoscustprofdevelopment', account_key='X1nmVm/GGg+UQLrDHBTfqxNRFvD4XI1GjnMCF2C2DvWT8pu+3qVI3BVt+2t2k0Ksz1PNPRoHgpqC9QOxmmZJcg==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viewSchema = StructType([StructField(\"idd\", IntegerType(), False), StructField(\"cid\", IntegerType(), False),\n",
    "                             StructField(\"pid\", IntegerType(), False),\n",
    "                             StructField(\"rating\", IntegerType(), False)])\n",
    "                             \n",
    "viewings = sc.textFile(\"wasbs://sdcsparkrd01@asoscustprofdevelopment.blob.core.windows.net/test/customer_product_rating.csv\").map(lambda x: x.split(',')).map(lambda l: Rating(int(l[1]), int(l[2]), float(l[3])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranks = [2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "for i in range(0, len(ranks)):\n",
    "    rank = ranks[i]\n",
    "    numIterations = 5\n",
    "    reg = 0.001\n",
    "    alpha = 50\n",
    "    print(\"Train the model...\")\n",
    "    t_start = time.time()\n",
    "    model = ALS.trainImplicit(viewings, rank, numIterations, reg, alpha)\n",
    "    t_stop= time.time()\n",
    "    print t_stop - t_start\n",
    "    model = model.userFeatures()\n",
    "    model = model.map(lambda (x, y) : (x, ' '.join(str(e) for e in y)))\n",
    "    fname = \"mf_\" + rank[i]\n",
    "    model.toDF().coalesce(1).write.csv(\"wasb://sdcsparkrd01@asoscustprofdevelopment.blob.core.windows.net/\" + fname, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
